%\VignetteIndexEntry{flexsurv user guide}

%% TODO 
%% What examples of custom dist? llogis? tobit example in help(survreg)?  Walter's model
%% spline with haz as fn of time
%% fractional polynomials


\documentclass[nojss,nofooter]{jss}
\usepackage{bm}
\usepackage{tabularx}
\usepackage{graphics}

\author{Christopher H. Jackson \\ MRC Biostatistics Unit, Cambridge, UK \\ \email{chris.jackson@mrc-bsu.cam.ac.uk}}
\title{flexsurv: flexible parametric survival modelling in R}

\Abstract{ \pkg{flexsurv} is an R package for fully-parametric modelling of 
  survival data.  Any parametric time-to-event distribution
  may be fitted if the user supplies at minimum a probability density
  or hazard function.  Many standard survival distributions are built
  in, and also the three and four-parameter generalized gamma and F
  models.  Any parameter of the distribution can be modelled as a
  linear or log-linear function of covariates.  Another built-in model
  is the spline model of Royston and Parmar, in which both baseline
  survival and covariate effects can be arbitrarily flexible
  parametric functions of time.
 
  The main model-fitting function, \code{flexsurvreg}, uses the
  familiar syntax of \code{survreg} from the standard \pkg{survival}
  package --- censoring or left-truncation are specified in
  \code{Surv} objects.  Estimates and confidence intervals for any
  function of the model parameters can be printed or plotted.
  \pkg{flexsurv} also enhances the \pkg{mstate} package (Putter et al)
  by providing cumulative incidences for fully-parametric multi-state
  models.

  This article explains the methods and design principles of the
  package, giving several worked examples of its use.
}
\Keywords{survival}

\begin{document}

\section{Motivation and design}

The Cox model for survival data is ubiquitous in medical research, since the effects of
predictors can be estimated without needing to supply a
baseline survival distribution that might be inaccurate.  However,
fully-parametric models have many advantages, and even the originator
of the Cox model has expressed a preference for parametric modelling
\citep{reid:cox:conversation}.  Fully-specified models help to
understand the change in hazard through time, and help with prediction
and extrapolation. For example, the mean survival $E(T) =
\int_0^{\infty}S(t)$, used in health economic
evaluations \citep{latimer2013survival}, needs the survivor function
$S(t)$ to be fully-specified for all times $t$.

%% Cox "That's right, but since then various people have shown that
%% the answers are very insensitive to the parametric
%% formulation of the underlying distribution. And if you want
%% to do things like predict the outcome for a particular patient,
%% it's much more convenient to do that parametrically."

\pkg{flexsurv} allows parametric distributions of
arbitrary complexity to be fitted to survival data, gaining the
convenience of parametric modelling, while avoiding the risk of model
misspecification.  Built-in choices include splines with any number of
knots \citep{royston:parmar} and 3--4 parameter generalized gamma and
F distribution families.  Any user-defined model may be employed by
supplying at minimum an R function to compute the probability density
or hazard, and ideally also its cumulative form.  Any parameters may
be modelled in terms of covariates, and any function of the parameters
may be printed or plotted in model summaries.

\pkg{flexsurv} is intended as a general platform for survival
modelling in R.  It is similar in spirit to the Stata packages
\pkg{stpm2} \citep{stpm2} for spline-based survival modelling, and
\pkg{stgenreg} \citep{stgenreg} for fitting survival models with
user-defined hazard functions using numerical integration. The
\code{survreg} function in the R package \pkg{survival}
\citep{therneau:survival} only supports two-parameter (location/scale)
distributions, though users can supply their own distributions if they
can be parameterised in this form.  Many other contributed R packages
can fit survival models, e.g. \pkg{eha} \citep{eha}, \pkg{VGAM}
\citep{yee:wild}, though these are either limited to specific
distribution families, not specifically designed for survival analysis,
or (\pkg{ActuDistns}, \citet{actudistns}) contain only the definitions
of distribution functions.  \pkg{flexsurv} enables distribution
functions provided by such packages to be employed in models.  An
advantage over \pkg{stgenreg} is that numerical integration can be
avoided if the analytic cumulative distribution or hazard can be
supplied, and optimisation can also be speeded by supplying analytic
derivatives.  \pkg{flexsurv} also has features for multi-state
modelling and interval censoring, and general output reporting.  It
employs functional programming to work with user-defined or existing R
functions.



\section{General parametric survival model}

\subsection{Definitions} 

The general model that \pkg{flexsurv} fits has probability density function
\begin{equation}
  \label{eq:model}
  f(t | \mu(\mathbf{z}), \bm{\alpha}(\mathbf{z})), \quad t \geq 0  
\end{equation}

The cumulative distribution function $F(t)$, survivor
function $S(t) = 1 - F(t)$, cumulative hazard $H(t) = -\log S(t)$ and
hazard $h(t) = f(t)/S(t)$ are also defined (suppressing the conditioning for clarity).
$\mu=\alpha_0$ is the parameter of primary interest,
which usually governs the mean or location of the distribution.  Other
parameters $\bm{\alpha} = \alpha_1, \ldots, \alpha_R$ are called
``ancillary'' and determine the shape, variance or higher moments.

%%% Covariates may be time-dependent, but this notation generalizes to left-truncation, ref msm section 

\paragraph{Covariates} 

All parameters may depend on a vector of covariates $\mathbf{z}$
through link-transformed linear models $g_0(\mu) = \bm{\beta}_0^{'}
\mathbf{z}$ and $g_r(\alpha_r) = \bm{\beta}_r^{'} \mathbf{z}$. $g()$
will typically be $\log()$ if the parameter is defined to be positive,
or the identity function if the parameter is unrestricted.  In all
models, $\bm{\beta}$ includes at least an intercept, so that the full
set of parameters is given by $\{\bm{\beta}_r: r=0,\ldots,R$\}.

Suppose that the location, but not the ancillary parameters, depends
on covariates.  If the hazard function factorises as $h(t | \alpha,
\mu(\mathbf{z})) = \mu(\mathbf{z}) h_0(t | \alpha)$, then this is a
\emph{proportional hazards} (PH) model, so that the hazard ratio between
two groups (defined by different values of $\mathbf{z}$) is constant
over time.

Alternatively, if $S(t | \mu(\mathbf{z}), \alpha) =
S(\mu(\mathbf{z}) t | \alpha)$ then we have an \emph{accelerated
  failure time} (AFT) model, so that the effect of covariates is to speed or
slow the passage of time. For example, doubling the value of a
covariate with coefficient $\beta=\log(2)$ would give half the
expected survival time.


\paragraph{Data and likelihood} 

Let $t_i: i=1,\ldots, n$ be a sample of times from individuals $i$.
Let $c_i=1$ if $t_i$ is an observed death time, or $c_i=0$ if $t_i$ is
a right-censoring time, thus the true death time is known only to be
greater than $t_i$.  Also let $s_i$ be corresponding left-truncation
(or delayed-entry) times, meaning that individual $i$ is only observed
conditionally on having survived up to $s_i$, thus $s_i=0$ if there is
no left-truncation.  Additionally let $t^{max}_i$ be left-censoring
times.  If there is no left-censoring then these are infinite, so that
$S(t^{max}_i)=0$; or if the $i$th death time is interval-censored then
$c_i=0$ and $t^{max}_i$ is finite.

The likelihood for the parameters $\bm{\beta}$ in model
(\ref{eq:model}), given the corresponding data vectors, is
\begin{equation}
  \label{eq:lik}
  l(\{\bm{\beta}_r\} | \mathbf{t},\mathbf{c},\mathbf{s},\mathbf{t}^{max}) = \left\{ \prod_{i:\ c_i=1} f_i(t_i) \prod_{i:\ c_i=0} \left(S_i(t_i) - S_i(t^{max}_i)\right)\right\} / \prod_i S_i(s_i)  
\end{equation}

Note that the individuals are independent, so that \pkg{flexsurv} does not
currently support frailty, clustered or random effects models.

An example dataset used throughout this paper is from 686 patients
with primary node positive breast cancer, available in the package as
\code{bc}. This was originally provided with \code{stpm} \citet{stpm:orig},
and analysed in much more detail by \citet{royston:parmar} and
\citet{sauerbrei1999building}.


\section{Model fitting syntax} 

The main model-fitting function is called \code{flexsurvreg}.  Its
first argument is an R \emph{formula} object.  The left hand side of
the formula gives the response as a survival object, using the
\code{Surv} function from the \pkg{survival} package.  Here, this
indicates that the response variable is \code{recyrs}, and that these
are observed death and censoring times when the variable
\code{censrec} is 1 or 0 respectively.  The covariate \code{group} is
a factor representing prognostic score, with three levels
\code{"Good"} (the baseline), \code{"Medium"} and
\code{"Poor"}. All of these variables are in the data frame
\code{bc}.
<<>>=
library(flexsurv)
fs1 <- flexsurvreg(Surv(recyrs, censrec) ~ group, data=bc, dist="weibull")
@ 

If we also had left-truncation times in a variable called
\code{start}, the response would be \\ \code{Surv(start,recyrs,censrec)}.
Or if all responses were interval-censored between lower and upper
bounds \code{tmin} and \code{tmax}, then we would write
\code{Surv(tmin,tmax,type="interval2")}.

If the argument \code{dist} is a string, this denotes a built-in
survival distribution, in this case the Weibull.   
Printing the fitted model object gives estimates and confidence
intervals for the model parameters and other useful information.  Note
that these are the \emph{same parameters} as represented by
the R distribution function
\code{dweibull}: the \code{shape} $\alpha$ and the \code{scale} $\mu$ of the survivor function
$S(t) = \exp(-(t/\mu)^\alpha)$.  
<<>>=
fs1
@ 
The same model can be fitted using \code{survreg} in 
\pkg{survival}:
<<>>=
survreg(Surv(recyrs, censrec) ~ group, data=bc, dist="weibull")
@
The maximised log-likelihoods are the same, however the
parameterisation is different: the first coefficient
\code{(Intercept)} reported by \code{survreg} is $\log(\mu)$, and
\code{survreg}'s \code{"scale"} is \code{dweibull}'s (thus
\code{flexsurvreg})'s 1 / \code{shape}. The covariate effects $\bm{\beta}$,
however, have the same "accelerated failure time" interpretation, as
linear effects on $\log(\mu)$.  The multiplicative effects $\exp(\bm{\beta})$
are provided in the output as \code{exp{est}}.

\subsection{Built-in survival models}

\code{flexsurvreg}'s currently built-in distributions are listed in Table
\ref{tab:dists}.  In each case, the probability density $f()$ and
parameters used in the fitted model are taken from an existing R
function of the same name but beginning with the letter \code{d}.  For
the Weibull, exponential (\code{dexp}), gamma (\code{dgamma}) and
log-normal (\code{dlnorm}), the density functions are provided with
standard installations of R.  

\pkg{flexsurv} provides some additional survival distributions,
including a Gompertz distribution with unrestricted shape parameter
(\code{dist="gompertz"}), and the three- and four-parameter families
described below.  For all built-in distributions, \pkg{flexsurv} also
defines functions beginning \code{h} giving the hazard, and \code{H}
for cumulative hazard.

\paragraph{Generalized gamma} This three-parameter distribution
includes the Weibull, gamma and log-normal as special cases.  The
original parameterisation from \citet{stacy:gengamma} is available as\\
\code{dist="gengamma.orig"}, however the newer parameterisation
\citep{prentice:loggamma} is preferred: \code{dist="gengamma"}.  This has
parameters ($\mu$,$\sigma$,$q$), and survivor function
\[
\begin{array}{ll}
1 - I(\gamma,u)   & (q > 0)\\
1 - \Phi(z)  & (q = 0)\\
\end{array}
\]
where $I(a,x) = \int_0^x x^{a-1}\exp(-x)/\Gamma(a)$ is the incomplete gamma function (the cumulative gamma distribution with shape $a$ and scale 1), $\Phi$ is the standard normal cumulative distribution,  $u = \gamma \exp(|q|z)$, $z=(\log(t) - \mu)/\sigma$, and $\gamma=q^{-2}$.   The \citet{prentice:loggamma} parameterisation extends the original one to include a further class of models with negative $q$, and survivor function $I(\gamma,u)$, where $z$ is replaced by $-z$.   This stabilises estimation when the distribution is close to log-normal, since $q=0$ is no longer near the boundary of the parameter space.    In R notation, \footnote{The parameter called $q$ here and in previous literature is called $Q$ in \code{dgengamma} and related functions, since the first argument of a cumulative distribution function is conventionally named \code{q}, for quantile, in R.} the parameter values corresponding to the three special cases are

\begin{Code}
dgengamma(x, mu, sigma, Q=0)     ==  dlnorm(x, mu, sigma)                                
dgengamma(x, mu, sigma, Q=1)     ==  dweibull(x, shape=1/sigma, scale=exp(mu))           
dgengamma(x, mu, sigma, Q=sigma) ==  dgamma(x, shape=1/sigma^2, 
                                               rate=exp(-mu) / sigma^2)  
\end{Code}

The generalized gamma model is fitted to the breast cancer survival
data. The first \code{fs2} is an AFT model, where only the parameter
$\mu$ depends on the prognostic covariate \code{group}.  In a second
model \code{fs3}, the first ancillary parameter \code{sigma} also
depends on this covariate, giving a model with a time-dependent effect
that is neither PH nor AFT.  The second ancillary parameter \code{Q}
is still common between prognostic groups.
<<>>=
fs2 <- flexsurvreg(Surv(recyrs, censrec) ~ group, data=bc, dist="gengamma")
fs3 <- flexsurvreg(Surv(recyrs, censrec) ~ group + sigma(group), 
                   data=bc, dist="gengamma")
@ 
SHOW IT FITS BETTER, LIKS, AIC, PLOTS

\paragraph{Generalized F} This four-parameter distribution includes
the generalized gamma, and also the log-logistic, as special cases.
The variety of hazard shapes that can be represented is discussed by
\citet{ccox:genf}.  It is provided here in alternative ``original''
(\code{dist="genf.orig"}) and ``stable'' parameterisations
(\code{dist="genf"}) as presented by \citet{prentice:genf}. 
See \code{help(GenF)} and \code{help(GenF.orig)} in the package documentation 
for the exact definitions.


\begin{table}
  \begin{tabular}{llll}
\hline
    &  Parameters &  Density R function & \code{dist}\\
\hline
    Exponential & \code{rate}             & \code{dexp}   & \code{"exp"} \\
    Weibull     & \code{shape, scale}     & \code{dweibull} & \code{"weibull"} \\
    Gamma       & \code{shape, rate}      & \code{dgamma} & \code{"gamma"}\\
    Log-normal  & \code{meanlog, sdlog}   & \code{dlnorm} & \code{"lnorm"}\\
    Gompertz    & \code{shape, rate}      & \code{dgompertz} & \code{"gompertz"} \\
    Generalized gamma (Prentice 1975)   & \code{mu, sigma, Q} & \code{dgengamma} & \code{"gengamma"} \\
    Generalized gamma (Stacy 1962)& \code{shape, scale, k} & \code{dgengamma.orig} & \code{"gengamma.orig"} \\
    Generalized F     (stable)    & \code{mu, sigma, Q, P} & \code{dgenf} & \code{"genf"} \\
    Generalized F     (original)  & \code{mu, sigma, s1, s2} & \code{dgenf.orig} & \code{"genf.orig"} \\
\hline
  \end{tabular}
  \caption{Built-in parametric survival distributions in \pkg{flexsurv}}
  \label{tab:dists}
\end{table}

\subsection{Plotting outputs}

The \code{plot()} method for \code{flexsurvreg} objects is used as a
quick check of model fit.  By default, this draws a Kaplan-Meier
estimate of the survivor function $S(t)$, one for each combination of
categorical covariates, or just a single ``population average'' curve if there are no
categorical covariates.  The corresponding estimates from the fitted
model are overlaid.  Fitted values from further models can be added
with the \code{lines()} method.  
\begin{figure}
  \centering
<<fig=TRUE>>=
plot(fs1, col="gray", lwd.obs=2)
lines(fs2, col="red", lty=2)
lines(fs3, col="red")
@ 
  \caption{Estimated survival from parametric models and Kaplan-Meier estimates.}
  \label{fig:surv}
\end{figure}
\code{scale="hazard"} can be used to plot hazards from parametric
models against kernel density estimates (obtained from \pkg{muhaz};
citet{muhaz,mueller:wang}).  This shows more clearly why the Weibull
model is inadequate: the hazard must be increasing or decreasing ---
while the generalized gamma can represent the increase and subsequent
decline in hazard seen in the data.
\begin{figure}
  \centering
<<fig=TRUE>>=
plot(fs1, type="hazard", col="gray", lwd.obs=2)
lines(fs2, type="hazard", col="red", lty=2)
lines(fs3, type="hazard", col="red")
@ 
  \caption{Estimated hazards from parametric models and kernel density estimates.}
  \label{fig:surv}
\end{figure}

Similarly, \code{scale="cumhaz"} plots cumulative hazards. In fact any
function of the parameters can be plotted, see EXAMPLE.

For more customisable plots, it is advised to set up the axes
beforehand, and use the \code{lines()} method.  Or for even more
flexibility, the data underlying the plots is available from the
\code{summary.flexsurvreg()} method.

In this example, there is only a single categorical covariate, and the
\code{plot} and \code{summary} methods return one observed and fitted
trajectory for each level of that covariate.  For more complicated
models, users should specify exactly what covariate values they
want summaries for, rather than relying on the default \footnote{If there are only factor covariates, all combinations are plotted.  If
there are any continuous covariates, these methods by default return a ``population average''
curve, with the linear model design matrix set to its average
values, including the 0/1 contrasts defining factors, which doesn't
represent a meaningful covariate combination.}.
This is done by

EXAMPLE 



\subsection{Supplying custom distributions}

\pkg{flexsurv} is not limited to its built-in distributions.  Any
survival model of the form (\ref{eq:model}--\ref{eq:lik}) can be
fitted if we can provide either the density function $f()$ or the
hazard $h()$.  Many contributed R packages provide probability density
and cumulative distribution functions for positive distributions.  
Though survival models may be more naturally characterised by their
hazard function, representing the changing risk of death through time.
For example, for survival following major surgery we may want a
``U-shaped'' hazard curve, representing a high risk soon after the
operation, which then decreases, but increases naturally as survivors
grow older.

To supply a custom distribution, the \code{dist} argument to
\code{flexsurvreg} is defined to be an R list object, rather than a
character string.  The list has the following elements.

\begin{description}
\item[\code{name}] Name of the distribution.  For example, if this is \code{"llogis"} then there are assumed to be at least either a function called \code{d} to compute the probability density or \code{h} to compute the hazard.  Ideally there will also be a function called \code{p} for the cumulative distribution (if \code{d} is given}, or \code{H} for the cumulative hazard (to complement \code{h}).
  These functions must be \emph{vectorised}.   SEE EXAMPLE BELOW
\item[\code{pars}] Character vector naming the parameters of the distribution $\mu,\alpha_1,...,\alpha_R$.
\item[\code{location}] Quoted name of the location parameter $\mu$.
\item[\code{transforms}] A list of functions $g()$ which transform the parameter from its natural range to the real line, for example, \code{c(log,identity)} \footnote{Note this is a \emph{list}, not an \emph{atomic vector} of functions, so if the distribution only has one parameter, we shoudl write \code{transforms=c(log)} or \code{transforms=list(log)}, not \code{transforms=log}}
\item[\code{inv.transforms}] List of corresponding inverse functions.
\item[\code{inits}] A function which returns initial values of the parameters for maximum likelihood estimation.    TRICKY
\end{description}
    
\paragraph{Example: Using functions from a contributed package}

The following custom model uses the log-logistic distribution function
(\code{dllogis} and \code{pllogis}) available in the package
\pkg{eha}.   This has two parameters DISCUSS.   INITIAL VALUES?

%% survivor function 1/ (1 + (x/b)^a)
%% log(1/S(t) - 1) is linear function of log time.  proportional odds

<<>>=
library(eha)
custom.llogis <- list(name="llogis",  pars=c("shape","scale"), location="scale",
                      transforms=c(log, log), inv.transforms=c(exp, exp),
                      inits=function(t){ c(1, median(t)) })
fs4 <- flexsurvreg(Surv(recyrs, censrec) ~ group, data=bc, dist=custom.llogis)
@ 

This fits the breast cancer data better than the Weibull, since it can
represent a peaked hazard, but less well than the generalized gamma.
Proportional odds.  ANY SPACE FOR A HIGHLIGHTED PLOT


The distribution exists in another package, but may be parameterised 
Example: Gompertz-Makeham -- say it doesn't converge, the parameters aren't identifiable 

\paragraph{Example: Wrapping functions from a contributed package}

Sometimes there may be probability density and similar functions in a
contributed package, but in a different format.  For example,
\pkg{eha} also provides a three-parameter Gompertz-Makeham
distribution with density \code{dmakeham}, whose shape parameters are
provided to as a vector of length two.  However, \code{flexsurvreg}
expects its distribution functions to have one argument for each
parameter.  Therefore we write our own functions that wrap around 
the third-party functions.
<<>>=
dmakeham3 <- function(x, shape1, shape2, scale, ...)  {
    dmakeham(x, shape=c(shape1, shape2), scale=scale, ...)
}
pmakeham3 <- function(q, shape1, shape2, scale, ...)  {
    pmakeham(q, shape=c(shape1, shape2), scale=scale, ...)
}
@ 
\code{flexsurvreg} also requires these functions to be
\emph{vectorized}.  That is, we can supply a vector of alternative
values for each argument and expect a vector of the same length to be
returned.  The R base function \code{Vectorize} can be used 
to do this here.
<<>>=
dmakeham3 <- Vectorize(dmakeham3) 
pmakeham3 <- Vectorize(pmakeham3)
@ 
and this allows us to write, for example, 
<<>>=
pmakeham3(c(0, 1, 1, Inf), c(1, 1, 2, 1), 1, 1)
@ 
Our functions 
\begin{Scode}
custom.makeham <- list(name="makeham3",
                       pars=c("shape1","shape2","scale"),
\end{Scode}

Functions need to be vectorised 
density functions need a log argument

\paragraph{Example: Changing the parameterisation of a distribution}

(talk about Weibull prop haz model, GG PH)
refer back to Weibull model presentation
refer back to GG presentation 

\paragraph{Example: Omitting the cumulative distribution or hazard}

If there is no analytic form for $F(t)$ or $H(t)$ as the integral of
the density or hazard respectively, then \pkg{flexsurv} can compute
these internally by numerical integration, though this will
substantially slow down the computation.  The default options of the
built-in R routine \code{integrate} for adaptive quadrature are used,
though these may be changed using the \code{integ.opts} argument to
\code{flexsurvreg}.


In Section \ref{sec:gdim} 


\subsection{Computation}

The likelihood is maximised using the optimisation methods available
through the standard R \code{optim} function.  By default, this is the
\code{"BFGS"} method (\citep{nash}) which can use the analytic
derivatives of the likelihood with respect to the model parameters, if
these are available, to improve the speed of convergence to the
maximum.

For custom distributions, the user can optionally supply functions
with names beginning \code{"DLd"} and \code{"DLS"} respectively
(e.g. \code{DLdweibull,DLSweibull}) to calculate the derivatives of
the log density and log survivor functions with respect to the
transformed parameters $\gamma$.

Initial values are difficult: ideally two would come from moments of
the distribution, then defaults that reduce to simpler distributions.
example

Demo on at least one dataset: stgenreg uses bc example i think




\subsection{Output functions}

\code{summary.flexsurvreg} calculates the estimated survival, hazard
or cumulative hazard at a series of times and for specified covariate
values. Confidence intervals are produced by simulating a large sample
from the asymptotic normal distribution of the maximum likelihood
estimates $\gamma$ OR WHATEVER, via the function
\code{normboot.flexsurvreg}.  The default \code{plot} method for
\code{flexsurvreg} objects graphs these fitted trajectories against
non-parametric estimates based on Kaplan-Meier or kernel estimation
(REF muhaz), while the \code{lines} method adds lines to an existing
plot.  REFER TO EXAMPLE FIGURE

Any user-defined function of the basic model parameters $\gamma$ OR
WHATEVER and time can also be summarised in the same way.  For
example, in a non-proportional hazards model, the hazard ratio between
two groups of interest varies through time.  To plot this trajectory,
and confidence intervals.   EXAMPLE FROM SPLINE. 

Restricted mean survival: say of interest. ref royston + parmar


\section{Any-dimension models}

\pkg{flexsurv} also supports models where the number of parameters is
arbitrary.  In the models discussed previously, the number of
parameters in the model family is fixed (e.g. three for the
generalized gamma).  Here the model complexity can be chosen by the
user.  We may want to represent more irregular hazard
curves by more flexible functions, or use bigger models if a bigger
sample size makes it feasible to estimate more parameters.


\subsection{Royston and Parmar spline model}

In the spline-based survival model of \citet{royston:parmar}, a
transformation $g(S(t,z))$ of the survival function is modelled as a
natural cubic spline function of log time, $x = \log(t)$, plus linear
effects of covariates $z$.  This is available here as the function
\code{flexsurvspline},  and is also available in the Stata package
\code{stpm2} \citep{stpm2} (and historically \code{stpm}, \citet{stpm:orig,stpm:update}).

  \[g(S(t,z)) = s(x, \bm{\gamma})\]

Typically we use $g(S(t,\mathbf{z}) = \log(-\log(S(t,\mathbf{z}))) =
\log(H(t,\mathbf{z}))$, the log cumulative hazard, giving a
proportional hazards model.    

\paragraph{Spline parameterisation}
The complexity of the model, thus the dimension of $\bm{\gamma}$, is
governed by the number of \emph{knots} $m$ in the spline function
$s()$.  Natural cubic splines are piecewise cubic polynomials defined
to be continuous, with continuous first and second derivatives at the
knots, and also constrained to be linear beyond boundary knots
$k_{min},k_{max}$.  As well as the boundary knots there may be up to
$m\geq 0$ \emph{internal} knots $k_1,\ldots k_m$.  Various spline
parameterisations exist --- the one used here is from
\citet{royston:parmar}.
\begin{equation}
  \label{eq:spline}
  s(x,\bm{\gamma}) = \gamma_0 + \gamma_1 x + \gamma_2 v_1(x) + \ldots + \gamma_{m+1} v_m(x)   
\end{equation}


where $v_j(x)$ is the $j$th \emph{basis} function

\[v_j(x) = (x - k_j)^3_+ - \lambda_j(x - k_{min})^3_+ - (1 - \lambda_j) (x - k_{max})^3_+, 
\qquad
\lambda_j = \frac{k_{max} - k_j}{k_{max} - k_{min}} \] 

and $(x - a)_+ = max(0, x - a)$.  If $m=0$ then there are only two
parameters $\gamma_0,\gamma_1$ --- in fact if $g()$ is the log
cumulative hazard, this is equivalent to a Weibull model (PARAMETERS /
DPQR STATEMENT).  Table \ref{tab:spline} explains two alternative
choices of $g()$.
  
  \begin{table}
  \begin{tabularx}{\textwidth}{lXll}
\hline
    Model &  $g(S(t,\mathbf{z}))$ & In \code{flexsurvspline} & With $m=0$ \\
\hline
    Proportional hazards & $\log(-\log(S(t,\mathbf{z})))$ \newline {\footnotesize (log cumulative hazard)}  & \code{scale="hazard"} & Weibull\\
    Proportional odds    & $\log(S(t,\mathbf{z})^{-1} - 1)$ \newline {\footnotesize (log cumulative odds)}   & \code{scale="odds"} & Log-logistic\\
    Normal / probit      & $\Phi^{-1}(S(t,\mathbf{z}))$  \newline   {\footnotesize (inverse normal CDF, \code{qnorm})}    & \code{scale="normal"} & Log-normal \\  
\hline
  \end{tabularx}    
    \caption{Alternative modelling scales for \code{flexsurvspline}}
    \label{tab:spline}
\end{table}

\paragraph{Covariates on spline parameters}
Covariates can be placed on any parameter $\gamma$ through a linear
model (with identity link function).  Most straightforwardly we can
let the intercept $\gamma_0$ vary with covariates $\mathbf{z}$, giving
a proportional hazards or odds model (depending on $g()$).

\[g(S(t,z)) = s(x, \bm{\gamma}) + \bm{\beta}^T \mathbf{z} \]

FLEXSURVSPLINE COMMAND

The spline coefficients $\gamma_j: j=1, 2 \ldots$, the "ancillary parameters",
may also be modelled as linear functions of covariates $\mathbf{z}$, as

\[\gamma_j(\mathbf{z}) = \gamma_{j0} + \gamma_{j1}z_1 + \gamma_{j2}z_2 + \ldots\]

giving a model where the effects of covariates are arbitrarily flexible
functions of time: a non-proportional hazards or odds model.

FLEXSURVSPLINE COMMAND

Demo on at least one dataset 

DPQR STATEMENTS


\subsection{General-dimension models}
\label{sec:gdim}

The spline model above is an example of the general parametric form
(\ref{eq:model}), but the number of parameters ($R+1$ in
(\ref{eq:model}), $m+2$ in (\ref{eq:spline})) is arbitrary.
\pkg{flexsurv} has the tools to deal with any model of this form.
\code{flexsurvspline} works internally by building a custom
distribution and then calling \code{flexsurvreg}.  Similar models may
in principle be built by users using the same method.  This relies on
a functional programming trick.

\paragraph{Creating distribution functions dynamically}

The R distribution functions supplied to custom models are expected to
have a fixed number of arguments, one for each scalar parameter.
However, the distribution functions for the spline model
(e.g. dsurvspline) have an argument \code{gamma} representing the
vector of parameters $\gamma$.  


To convert it into the correct form, \pkg{flexsurv} provides the
utility \code{unroll.function}.  This converts a function with one (or
more) vector parameters (matrix arguments) to a function with an
arbitrary number of scalar parameters (vector arguments).

Note the scalar \emph{parameters} can be supplied to the function as
correspond to vector \emph{arguments}, and vector parameters supplied
as \emph{matrix} arguments.

That is, \code{x},\code{shape} and \code{scale} in
\code{dweibull(x,shape,scale)} could actually be vectors representing
alternative values for the \code{x} or the parameters.  Similary
\code{gamma} in \code{dsurvspline(x, gamma,...)} could be a matrix,
  whose rows represent alternative sets of values for $\gamma$.

Due to vectorisation:  EXAMPLE



\paragraph{Example: splines on alternative scales}

stgenreg has demo of spline modelling on the log hazard scale.  Can we do this using a generic distribution? 
(advantage: when there are multiple time dependent effects, the
interpretation of the time-dependent hazard ratios is simplified as
they do not depend on values of other covariates, which is the case
when modelling on the cumulative hazard scale (Royston and Lambert
2011).

\paragraph{Example: fractional polynomials}

%fractional polynomials? 
%specified by number M and set of powers p1,...pM
%chosen from c(-2,-1,-0.5,0,0.5,1,2,3), including repeats, where x^0 = log(x)
%with repeated powers, each repeat multiplied by a power of log(x)

relation to fractional polynomials \citep{royston1994regression}

Note that both splines and fractional polynomials have only been used
here to express how risk changes through time --- they can also be
used for expressing non-linear effects of any continuous predictor,
see e.g. \citet{sauerbrei2007selection}, and several other
publications by the same authors, for a discussion and comparison.
This may be achieved here by using a suitable basis function of the
covariate EXAMPLE in the model formula.

Polyhazard models \citep{polyhazard} are another potential application
of this technique.  These express an overall hazard as a sum of latent
cause-specific hazards, although they may suffer from lack of
identifiability.  cite nikos, me

\section{Multi-state models}

A \emph{multi-state model} represents how an individual moves between
multiple states through time.  Survival analysis is a special case of
multi-state modelling with two states ``alive'' and ``dead''. Suppose
an individual is in state $S(t)$ at time $t$.  The next state to which
the individual moves, and the time of the change, are governed by a
set of \emph{transition intensities} $q_{rs}(t)$ for states $r, s =
1,\dots,R$, which for a survival model are equivalent to the hazard
$h(t)$.  The intensity represents the instantaneous risk of moving
from state $r$ to state $s$.

Suppose our data consist of a series of event times $t_{1},\dots,
t_{n}$, the last of these may be an observed event or censoring.  Any
software to fit survival models can also fit multi-state models to
this kind of data, provided it can deal with left-truncation or
\emph{counting process} data.

For more discussion of the theory see \citet{putter:mstate}. ref also
Andersen for CP data

\paragraph{Counting process data}
For each permitted $r \rightarrow s$ transition in the multi-state
model (ILLUSTRATION) there is a corresponding \emph{time-to-event
  model}, with cause-specific hazard rates defined by $q_{rs}(t)$. To
enable estimation of these hazards, the data are expressed as a series
of times to events which are potentially censored: $dt_{j} = t_{j+1} -
t_{j}: j = 1,\ldots,n-1$. For a patient who moves into state $s$ at
time $t_{j}$, their next event at $t_{j+1}$ is defined by the model
structure (FIGURE) to be one of a set of
competing events $s^*_1,\ldots,s^*_{n_s}$.

For example, in state EXAMPLE, the next state must either be EXAMPLE
or EXAMPLE so $n_s=EG$.  The time of the event which actually occurs
at $t_{j+1}$ is \emph{observed}, and the times of the \emph{competing}
events from this set (which have not occurred by this time) are
\emph{censored}.  Each $dt_{j}$ contributes an \emph{observed} time to
one of the EG transition-specific models, and a \emph{censored} time
to each of the models for the competing events.

FLEXSURVREG EXAMPLE

The \pkg{mstate} R package \citep{mstate:cmpb,mstate:jss} has a
utility \code{msprep} to produce data of this form from
``wide-format'' datasets where rows represent individuals, and times
of different events appear in different columns, and \pkg{mstate} has
a utility \code{msm2Surv} for 

illustrates Cox models
flexible parametric multi-state models 

\paragraph{Prediction from multi-state models}

Define cumulative incidence functions

The \code{mstate} package is designed to work with 
piecewise-constant cumulative incidence functions
baseline hazards are estimated non-parametrically 
\citep{mstate:cmpb,mstate:jss} 

function \code{msfit} that produces the cumulative incidences for each transition and a given covariate category, and their covariances, given a Cox model fitted using \code{coxph} from the \pkg{survival} package. 

Aalen-Johansen estimator,  simulation

contrast Markov and semi-Markov models

\paragraph{Multi-state models for panel data}

Note the contrast with multi-state models for \emph{panel data}, that is,
observations of the state of the process at a series of times
\citep{kalbfleisch:lawless}.  In panel data, we do not necessarily
know know the time of each transition, or even whether a transitions
of a certain type have occurred at all between a pair of observations.
Such models can be fitted with the \pkg{msm} package for R, but are
restricted to (piecewise) exponentially-distributed event times.



\code{survSplit} function in \pkg{survival} 


% cif in comp risks planned for stgenreg 
\section{Potential extensions}

relative survival
frailty 
many extensions may come from user-contributed models


\appendix
\section{Acknowledgements}
Thanks to Milan Bouchet-Valat.

\bibliography{flexsurv}

\end{document}
